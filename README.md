Replicating the Vision Transformer Architecture from "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale."
Paper: https://arxiv.org/abs/2010.11929

This is a step-by-step implementation of the "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" paper in PyTorch code. It opens with a brief discussion of the Transformer architecture, its application to a Computer Vision task, and the challenges compared to Convolutional Neural Networks. I then go through the machine learning workflow from data preprocessing and training a model, to utilizing transfer learning and hyperparamter tuning. Along the way, the mathematical equations of the original ViT paper are turned into clean PyTorch modules.
